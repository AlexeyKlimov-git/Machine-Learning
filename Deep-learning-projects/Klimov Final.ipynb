{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bTZNND14kYZ"
   },
   "source": [
    "# Распознавание рукописного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dW9L4RZ4p7t"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchtext\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5lhzOAO4zfP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1MSMT9L6iFk"
   },
   "outputs": [],
   "source": [
    " ! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcizdHV46iIJ"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 6368,
     "status": "ok",
     "timestamp": 1647024674688,
     "user": {
      "displayName": "Alexey Klimov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16102825217955361469"
     },
     "user_tz": -180
    },
    "id": "8UIWukZf6kSf",
    "outputId": "876146f1-c570-4d53-a8d2-7edb385575fa"
   },
   "outputs": [],
   "source": [
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1647024676458,
     "user": {
      "displayName": "Alexey Klimov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16102825217955361469"
     },
     "user_tz": -180
    },
    "id": "4URrtFFU6kUu",
    "outputId": "15db0e78-7404-4676-d7aa-0209a39a35cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    " ! mkdir /root/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1647024678336,
     "user": {
      "displayName": "Alexey Klimov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16102825217955361469"
     },
     "user_tz": -180
    },
    "id": "EXKaIBHu6kW2"
   },
   "outputs": [],
   "source": [
    "! cp kaggle.json /root/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1647024644104,
     "user": {
      "displayName": "Alexey Klimov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16102825217955361469"
     },
     "user_tz": -180
    },
    "id": "0rr51NkS6kY4"
   },
   "outputs": [],
   "source": [
    "! chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1647024681618,
     "user": {
      "displayName": "Alexey Klimov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16102825217955361469"
     },
     "user_tz": -180
    },
    "id": "s-_dYYDD6-2n",
    "outputId": "ccb12792-b88d-44ed-f8ac-d85e2989fbf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 - Unauthorized\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d bittlingmayer/amazonreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1647025518380,
     "user": {
      "displayName": "Alexey Klimov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16102825217955361469"
     },
     "user_tz": -180
    },
    "id": "6n0Ebd5NXuob",
    "outputId": "f9482874-cb8b-4b79-a260-d803b6829e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 - Unauthorized\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d heptapod/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHhvbLFd5Iud"
   },
   "outputs": [],
   "source": [
    "class Hparams():\n",
    "    def __init__(self):\n",
    "        self.chars = []\n",
    "            \n",
    "        self.lr = 0.001\n",
    "        self.batch_size = 64\n",
    "        self.hidden = 512\n",
    "        self.enc_layers = 2\n",
    "        self.dec_layers = 2\n",
    "        self.nhead = 4\n",
    "        self.dropout = 0.0\n",
    "        \n",
    "\n",
    "        self.width = 256\n",
    "        self.height = 64\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "hp = Hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4l5Ykvb5wRt"
   },
   "outputs": [],
   "source": [
    "# text to array of indicies\n",
    "def text_to_labels(s, char2idx):\n",
    "    return [char2idx['SOS']] + [char2idx[i] for i in s if i in char2idx.keys()] + [char2idx['EOS']]\n",
    "\n",
    "# convert images and labels into defined data structures\n",
    "def process_data(image_dir, labels_dir, ignore=[]):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    image_dir : str\n",
    "      path to directory with images\n",
    "    labels_dir : str\n",
    "      path to tsv file with labels\n",
    "    returns\n",
    "    ---\n",
    "    img2label : dict\n",
    "      keys are names of images and values are correspondent labels\n",
    "    chars : list\n",
    "      all unique chars used in data\n",
    "    all_labels : list\n",
    "    \"\"\"\n",
    "\n",
    "    chars = []\n",
    "    img2label = dict()\n",
    "\n",
    "    raw = open(labels_dir, 'r', encoding='utf-8').read()\n",
    "    temp = raw.split('\\n')\n",
    "    for t in temp:\n",
    "        try:\n",
    "            x = t.split(',')\n",
    "            flag = False\n",
    "            for item in ignore:\n",
    "                if item in x[1]:\n",
    "                    flag = True\n",
    "            if flag == False:\n",
    "                img2label[image_dir + x[0]] = x[1]\n",
    "                for char in x[1]:\n",
    "                    if char not in chars:\n",
    "                        chars.append(char)\n",
    "        except:\n",
    "            print('ValueError:', x)\n",
    "            pass\n",
    "\n",
    "    all_labels = sorted(list(set(list(img2label.values()))))\n",
    "    chars.sort()\n",
    "    chars = ['PAD', 'SOS'] + chars + ['EOS']\n",
    "\n",
    "    return img2label, chars, all_labels\n",
    "\n",
    "# MAKE TEXT TO BE THE SAME LENGTH\n",
    "class TextCollate():\n",
    "    def __call__(self, batch):\n",
    "        x_padded = []\n",
    "        max_y_len = max([i[1].size(0) for i in batch])\n",
    "        y_padded = torch.LongTensor(max_y_len, len(batch))\n",
    "        y_padded.zero_()\n",
    "\n",
    "        for i in range(len(batch)):\n",
    "            x_padded.append(batch[i][0].unsqueeze(0))\n",
    "            y = batch[i][1]\n",
    "            y_padded[:y.size(0), i] = y\n",
    "\n",
    "        x_padded = torch.cat(x_padded)\n",
    "        return x_padded, y_padded\n",
    "\n",
    "\n",
    "# TRANSLATE INDICIES TO TEXT\n",
    "def labels_to_text(s, idx2char):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    idx2char : dict\n",
    "        keys : int\n",
    "            indicies of characters\n",
    "        values : str\n",
    "            characters\n",
    "    returns\n",
    "    ---\n",
    "    S : str\n",
    "    \"\"\"\n",
    "    S = \"\".join([idx2char[i] for i in s])\n",
    "    if S.find('EOS') == -1:\n",
    "        return S\n",
    "    else:\n",
    "        return S[:S.find('EOS')]\n",
    "\n",
    "\n",
    "# COMPUTE CHARACTER ERROR RATE\n",
    "def char_error_rate(p_seq1, p_seq2):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    p_seq1 : str\n",
    "    p_seq2 : str\n",
    "    returns\n",
    "    ---\n",
    "    cer : float\n",
    "    \"\"\"\n",
    "    p_vocab = set(p_seq1 + p_seq2)\n",
    "    p2c = dict(zip(p_vocab, range(len(p_vocab))))\n",
    "    c_seq1 = [chr(p2c[p]) for p in p_seq1]\n",
    "    c_seq2 = [chr(p2c[p]) for p in p_seq2]\n",
    "    return editdistance.eval(''.join(c_seq1),\n",
    "                             ''.join(c_seq2)) / max(len(c_seq1), len(c_seq2))\n",
    "\n",
    "\n",
    "# RESIZE AND NORMALIZE IMAGE\n",
    "def process_image(img):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    ---\n",
    "    img : np.array\n",
    "    returns\n",
    "    ---\n",
    "    img : np.array\n",
    "    \"\"\"\n",
    "    w, h, _ = img.shape\n",
    "    new_w = hp.height\n",
    "    new_h = int(h * (new_w / w))\n",
    "    img = cv2.resize(img, (new_h, new_w))\n",
    "    w, h, _ = img.shape\n",
    "\n",
    "    img = img.astype('float32')\n",
    "\n",
    "    new_h = hp.width\n",
    "    if h < new_h:\n",
    "        add_zeros = np.full((w, new_h - h, 3), 255)\n",
    "        img = np.concatenate((img, add_zeros), axis=1)\n",
    "\n",
    "    if h > new_h:\n",
    "        img = cv2.resize(img, (new_h, new_w))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# GENERATE IMAGES FROM FOLDER\n",
    "def generate_data(img_paths):\n",
    "    \"\"\"\n",
    "    params\n",
    "    ---\n",
    "    names : list of str\n",
    "        paths to images\n",
    "    returns\n",
    "    ---\n",
    "    data_images : list of np.array\n",
    "        images in np.array format\n",
    "    \"\"\"\n",
    "    data_images = []\n",
    "    for path in tqdm(img_paths):\n",
    "        img = cv2.imread(path)\n",
    "        try:\n",
    "            img = process_image(img)\n",
    "            data_images.append(img.astype('uint8'))\n",
    "        except:\n",
    "            print('ERROR:',path)\n",
    "            #img = process_image(img)\n",
    "    return data_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ah68Ypm50p-"
   },
   "outputs": [],
   "source": [
    "# store list of images' names (in directory) and does some operations with images\n",
    "class TextLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_name, labels, char2idx, idx2char, eval=False):\n",
    "        \"\"\"\n",
    "        params\n",
    "        ---\n",
    "        images_name : list\n",
    "            list of names of images (paths to images)\n",
    "        labels : list\n",
    "            list of labels to correspondent images from images_name list\n",
    "        char2idx : dict\n",
    "        idx2char : dict\n",
    "        \"\"\"\n",
    "        self.images_name = images_name\n",
    "        self.labels = labels\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.eval = eval\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            #p.torch_transform(),  # random distortion and shear\n",
    "            # transforms.Resize((int(hp.height *1.05), int(hp.width *1.05))),\n",
    "            # transforms.RandomCrop((hp.height, hp.width)),\n",
    "            # transforms.ColorJitter(contrast=(0.5,1),saturation=(0.5,1)),\n",
    "            #transforms.RandomRotation(degrees=(-9, 9), fill=255),\n",
    "            # transforms.RandomAffine(10 ,None ,[0.6 ,1] ,3 ,fillcolor=255),\n",
    "            transforms.transforms.GaussianBlur(3, sigma=(0.1, 1.9)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def _transform(self, X):\n",
    "        j = np.random.randint(0, 3, 1)[0]\n",
    "        if j == 0:\n",
    "            return self.transform(X)\n",
    "        if j == 1:\n",
    "            return tt(ld(vignet(X)))\n",
    "        if j == 2:\n",
    "            return tt(ld(un(X)))\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images_name[index]\n",
    "        if not self.eval:\n",
    "            img = self.transform(img)\n",
    "            img = img / img.max()\n",
    "            img = img ** (random.random() * 0.7 + 0.6)\n",
    "        else:\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            img = img / img.max()\n",
    "\n",
    "        label = text_to_labels(self.labels[index], self.char2idx)\n",
    "        return (torch.FloatTensor(img), torch.LongTensor(label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "error",
     "timestamp": 1647017727037,
     "user": {
      "displayName": "Alexey Klimov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16102825217955361469"
     },
     "user_tz": -180
    },
    "id": "QcTpaKuI54H3",
    "outputId": "63ae4169-a937-44dd-bb34-8c5b72a50870"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-85d0dd617693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg2label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/handwriting-recognition/train_v2/train/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../input/handwriting-recognition/written_name_train_v2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchar2idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0midx2char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-78eef654ebee>\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(image_dir, labels_dir, ignore)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mimg2label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/handwriting-recognition/written_name_train_v2.csv'"
     ]
    }
   ],
   "source": [
    "img2label, chars, all_words = process_data(\"../input/handwriting-recognition/train_v2/train/\", \"../input/handwriting-recognition/written_name_train_v2.csv\")\n",
    "X_train, y_train = [], []\n",
    "hp.chars = chars\n",
    "char2idx = {char: idx for idx, char in enumerate(hp.chars)}\n",
    "idx2char = {idx: char for idx, char in enumerate(hp.chars)}\n",
    "items = list(img2label.items())[1000:190000] # a dataset is too big for size of 256x64, so, it needs to be trained by part.\n",
    "random.shuffle(items)\n",
    "for i, item in enumerate(items):\n",
    "    X_train.append(item[0])\n",
    "    y_train.append(item[1])\n",
    "\n",
    "X_train = generate_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04QHC7gk6BCx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMG5B/9ZkTCrDmcBMwDUdBP",
   "name": "Климов Алексей Витальевич - Финальный проект .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
